name: Production Data Collection

on:
  schedule:
    # Daily at 3 AM Phoenix time (10 AM UTC)
    - cron: '0 10 * * *'
  workflow_dispatch:
    inputs:
      zip_codes:
        description: 'ZIP codes (comma-separated)'
        required: false
        type: string
        default: '85031,85033,85035'
      collection_mode:
        description: 'Collection mode'
        required: false
        type: choice
        options: ['incremental', 'full', 'test']
        default: 'incremental'
      skip_llm:
        description: 'Skip LLM processing'
        required: false
        type: boolean
        default: false

permissions:
  contents: read
  issues: write

env:
  # Environment configuration
  ENVIRONMENT: production
  PYTHON_VERSION: "3.13"
  
  # Service configuration
  OLLAMA_URL: "http://localhost:11434"
  LLM_MODEL: "llama3.2:latest"
  
  # Timeout configuration
  COLLECTION_TIMEOUT: 75

concurrency:
  group: production-data-collection
  cancel-in-progress: false

jobs:
  collection-and-processing:
    name: Data Collection and Processing
    runs-on: ubuntu-latest
    timeout-minutes: 75
    environment: production
    
    outputs:
      collection-status: ${{ steps.status.outputs.collection-status }}
      processing-status: ${{ steps.status.outputs.processing-status }}
      properties-collected: ${{ steps.status.outputs.properties-collected }}
      
    steps:
    - uses: actions/checkout@v4
    
    - name: Pre-flight Secret Validation
      id: preflight-secrets
      env:
        MONGODB_URL: ${{ secrets.MONGODB_URL }}
        MARICOPA_API_KEY: ${{ secrets.MARICOPA_API_KEY }}
        WEBSHARE_API_KEY: ${{ secrets.WEBSHARE_API_KEY }}
        CAPTCHA_API_KEY: ${{ secrets.CAPTCHA_API_KEY }}
      run: |
        echo "🔍 Pre-flight secret validation started at $(date -u '+%Y-%m-%d %H:%M:%S UTC')"
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## Pre-flight Secret Validation" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Check all required secrets
        missing_secrets=()
        invalid_secrets=()
        
        # MongoDB URL validation
        if [[ -z "$MONGODB_URL" ]]; then
          missing_secrets+=("MONGODB_URL")
        elif [[ ! "$MONGODB_URL" =~ ^mongodb ]]; then
          invalid_secrets+=("MONGODB_URL: Invalid format (must start with 'mongodb')")
        else
          echo "✅ MONGODB_URL: Present and valid format" >> $GITHUB_STEP_SUMMARY
        fi
        
        # Maricopa API Key validation
        if [[ -z "$MARICOPA_API_KEY" ]]; then
          missing_secrets+=("MARICOPA_API_KEY")
        elif [[ ! "$MARICOPA_API_KEY" =~ ^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$ ]]; then
          invalid_secrets+=("MARICOPA_API_KEY: Invalid format (must be UUID)")
        else
          echo "✅ MARICOPA_API_KEY: Present and valid format" >> $GITHUB_STEP_SUMMARY
        fi
        
        # WebShare API Key validation
        if [[ -z "$WEBSHARE_API_KEY" ]]; then
          missing_secrets+=("WEBSHARE_API_KEY")
        else
          echo "✅ WEBSHARE_API_KEY: Present (length: ${#WEBSHARE_API_KEY})" >> $GITHUB_STEP_SUMMARY
        fi
        
        # Captcha API Key validation
        if [[ -z "$CAPTCHA_API_KEY" ]]; then
          missing_secrets+=("CAPTCHA_API_KEY")
        else
          echo "✅ CAPTCHA_API_KEY: Present (length: ${#CAPTCHA_API_KEY})" >> $GITHUB_STEP_SUMMARY
        fi
        
        # Determine validation result
        total_issues=$((${#missing_secrets[@]} + ${#invalid_secrets[@]}))
        
        if [[ $total_issues -eq 0 ]]; then
          echo "status=success" >> $GITHUB_OUTPUT
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "✅ **All secrets validated successfully**" >> $GITHUB_STEP_SUMMARY
        else
          echo "status=failed" >> $GITHUB_OUTPUT
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "❌ **Secret validation failed**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [[ ${#missing_secrets[@]} -gt 0 ]]; then
            echo "**Missing secrets:**" >> $GITHUB_STEP_SUMMARY
            for secret in "${missing_secrets[@]}"; do
              echo "- $secret" >> $GITHUB_STEP_SUMMARY
            done
            echo "" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [[ ${#invalid_secrets[@]} -gt 0 ]]; then
            echo "**Invalid secrets:**" >> $GITHUB_STEP_SUMMARY
            for secret in "${invalid_secrets[@]}"; do
              echo "- $secret" >> $GITHUB_STEP_SUMMARY
            done
            echo "" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "🚨 **Production data collection cannot proceed with invalid secrets**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Action Required:**" >> $GITHUB_STEP_SUMMARY
          echo "1. Fix secret configuration in Repository Settings → Secrets" >> $GITHUB_STEP_SUMMARY
          echo "2. Run secret validation workflow to verify fixes" >> $GITHUB_STEP_SUMMARY
          echo "3. Re-run this data collection workflow" >> $GITHUB_STEP_SUMMARY
          
          exit 1
        fi
    
    - name: Quick Service Connectivity Check
      if: steps.preflight-secrets.outputs.status == 'success'
      env:
        MONGODB_URL: ${{ secrets.MONGODB_URL }}
        MARICOPA_API_KEY: ${{ secrets.MARICOPA_API_KEY }}
        WEBSHARE_API_KEY: ${{ secrets.WEBSHARE_API_KEY }}
      run: |
        echo "🌐 Performing quick service connectivity checks..."
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### Service Connectivity Pre-flight" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Install minimal dependencies for connectivity tests
        pip install pymongo requests dnspython
        
        connectivity_failures=0
        
        # Test MongoDB Atlas connectivity (quick check)
        if timeout 15 python3 -c "
        import pymongo
        import sys
        try:
            client = pymongo.MongoClient('$MONGODB_URL', serverSelectionTimeoutMS=5000)
            client.server_info()
            print('MongoDB Atlas connection successful')
        except Exception as e:
            print(f'MongoDB connection failed: {e}')
            sys.exit(1)
        " 2>/dev/null; then
          echo "✅ MongoDB Atlas: Connection successful" >> $GITHUB_STEP_SUMMARY
        else
          echo "❌ MongoDB Atlas: Connection failed" >> $GITHUB_STEP_SUMMARY
          connectivity_failures=$((connectivity_failures + 1))
        fi
        
        # Test Maricopa API (lightweight check)
        if timeout 10 curl -f -s \
           -H "Authorization: Bearer $MARICOPA_API_KEY" \
           "https://api.mcassessor.maricopa.gov/v1/properties?limit=1" >/dev/null 2>&1; then
          echo "✅ Maricopa API: Connection successful" >> $GITHUB_STEP_SUMMARY
        else
          echo "❌ Maricopa API: Connection failed or unauthorized" >> $GITHUB_STEP_SUMMARY
          connectivity_failures=$((connectivity_failures + 1))
        fi
        
        # Test WebShare API (lightweight check)
        if timeout 10 curl -f -s \
           -H "Authorization: Token $WEBSHARE_API_KEY" \
           "https://proxy.webshare.io/api/v2/proxy/list/?limit=1" >/dev/null 2>&1; then
          echo "✅ WebShare API: Connection successful" >> $GITHUB_STEP_SUMMARY
        else
          echo "⚠️ WebShare API: Connection failed (will retry during collection)" >> $GITHUB_STEP_SUMMARY
          # Don't fail workflow for WebShare issues as they can be transient
        fi
        
        # Check if critical services are down
        if [[ $connectivity_failures -gt 1 ]]; then
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "🚨 **Multiple critical services unreachable**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Data collection is likely to fail. Consider:" >> $GITHUB_STEP_SUMMARY
          echo "1. Waiting for service recovery" >> $GITHUB_STEP_SUMMARY
          echo "2. Checking service status pages" >> $GITHUB_STEP_SUMMARY
          echo "3. Running comprehensive monitoring workflow" >> $GITHUB_STEP_SUMMARY
          echo "4. Manually triggering collection later" >> $GITHUB_STEP_SUMMARY
          exit 1
        elif [[ $connectivity_failures -gt 0 ]]; then
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "⚠️ Some services had connectivity issues but proceeding with collection" >> $GITHUB_STEP_SUMMARY
        else
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "✅ **All critical services reachable - proceeding with collection**" >> $GITHUB_STEP_SUMMARY
        fi
    
    - name: Environment setup
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        pip install uv
        uv sync --extra dev
    
    - name: Validate production environment
      env:
        ENVIRONMENT: ${{ env.ENVIRONMENT }}
        MONGODB_URL: ${{ secrets.MONGODB_URL }}
        MARICOPA_API_KEY: ${{ secrets.MARICOPA_API_KEY }}
        WEBSHARE_API_KEY: ${{ secrets.WEBSHARE_API_KEY }}
        CAPTCHA_API_KEY: ${{ secrets.CAPTCHA_API_KEY }}
        OLLAMA_URL: ${{ env.OLLAMA_URL }}
        LLM_MODEL: ${{ env.LLM_MODEL }}
      run: |
        echo "Validating production environment: $ENVIRONMENT"
        
        # Check required secrets
        missing_secrets=()
        [[ -z "$MONGODB_URL" ]] && missing_secrets+=("MONGODB_URL")
        [[ -z "$MARICOPA_API_KEY" ]] && missing_secrets+=("MARICOPA_API_KEY")
        [[ -z "$WEBSHARE_API_KEY" ]] && missing_secrets+=("WEBSHARE_API_KEY")
        [[ -z "$CAPTCHA_API_KEY" ]] && missing_secrets+=("CAPTCHA_API_KEY")
        
        if [ ${#missing_secrets[@]} -ne 0 ]; then
          echo "[FAIL] Missing production secrets: ${missing_secrets[*]}"
          exit 1
        fi
        
        echo "[OK] Environment validation passed"
        echo "Configuration: Environment=$ENVIRONMENT, LLM Model=$LLM_MODEL, Ollama URL=$OLLAMA_URL"
        
        # Setup directories
        mkdir -p data/{processed,raw,cookies} logs reports
    
    - name: Maricopa County data collection
      id: maricopa
      env:
        MARICOPA_API_KEY: ${{ secrets.MARICOPA_API_KEY }}
        ZIP_CODES: ${{ github.event.inputs.zip_codes || '85031,85033,85035' }}
        COLLECTION_MODE: ${{ github.event.inputs.collection_mode || 'incremental' }}
      run: |
        echo "Starting Maricopa County data collection..."
        echo "ZIP codes: $ZIP_CODES"
        echo "Collection mode: $COLLECTION_MODE"
        
        # Process each ZIP code
        IFS=',' read -ra ZIP_ARRAY <<< "$ZIP_CODES"
        total_collected=0
        
        for zip in "${ZIP_ARRAY[@]}"; do
          zip=$(echo "$zip" | xargs) # trim whitespace
          echo "Processing ZIP code: $zip"
          
          if uv run python scripts/testing/test_maricopa_collector.py --zip-code "$zip" --mode "$COLLECTION_MODE"; then
            collected=$(find data/raw -name "*${zip}*.json" 2>/dev/null | wc -l || echo "0")
            total_collected=$((total_collected + collected))
            echo "[OK] ZIP $zip: collected $collected properties"
          else
            echo "[WARN] ZIP $zip: collection failed"
          fi
        done
        
        echo "maricopa-collected=$total_collected" >> $GITHUB_OUTPUT
        echo "[OK] Maricopa collection completed: $total_collected properties"
      timeout-minutes: 30
    
    - name: Phoenix MLS data collection
      id: phoenix-mls
      if: success() || failure()
      env:
        WEBSHARE_API_KEY: ${{ secrets.WEBSHARE_API_KEY }}
        CAPTCHA_API_KEY: ${{ secrets.CAPTCHA_API_KEY }}
        ZIP_CODES: ${{ github.event.inputs.zip_codes || '85031,85033,85035' }}
        COLLECTION_MODE: ${{ github.event.inputs.collection_mode || 'incremental' }}
      run: |
        echo "Starting Phoenix MLS data collection..."
        
        # Install Playwright
        uv run playwright install chromium --with-deps
        
        # Run MLS collection
        if uv run python scripts/testing/test_phoenix_mls_with_services.py --zip-codes "$ZIP_CODES" --mode "$COLLECTION_MODE"; then
          mls_collected=$(find data/raw -name "*phoenix_mls*.json" 2>/dev/null | wc -l || echo "0")
          echo "mls-collected=$mls_collected" >> $GITHUB_OUTPUT
          echo "[OK] Phoenix MLS collection completed: $mls_collected properties"
        else
          echo "mls-collected=0" >> $GITHUB_OUTPUT
          echo "[WARN] Phoenix MLS collection failed"
        fi
      timeout-minutes: 25
    
    - name: Setup LLM service
      id: llm-setup
      if: (success() || failure()) && github.event.inputs.skip_llm != 'true'
      run: |
        echo "Setting up Ollama LLM service..."
        
        # Install and start Ollama
        curl -fsSL https://ollama.ai/install.sh | sh
        ollama serve > logs/ollama_server.log 2>&1 &
        
        # Wait for service and pull model
        sleep 15
        if ollama pull ${{ env.LLM_MODEL }}; then
          echo "llm-ready=true" >> $GITHUB_OUTPUT
          echo "[OK] LLM service ready with model ${{ env.LLM_MODEL }}"
        else
          echo "llm-ready=false" >> $GITHUB_OUTPUT
          echo "[WARN] LLM setup failed for model ${{ env.LLM_MODEL }}"
        fi
      timeout-minutes: 10
    
    - name: LLM data processing
      id: llm-processing
      if: steps.llm-setup.outputs.llm-ready == 'true'
      env:
        ENVIRONMENT: ${{ env.ENVIRONMENT }}
        MONGODB_URL: ${{ secrets.MONGODB_URL }}
        OLLAMA_URL: ${{ env.OLLAMA_URL }}
        LLM_MODEL: ${{ env.LLM_MODEL }}
        COLLECTION_MODE: ${{ github.event.inputs.collection_mode || 'incremental' }}
      run: |
        echo "Starting LLM data processing..."
        
        # Run LLM processing
        if uv run python scripts/testing/run_llm_e2e_tests.py --mode "$COLLECTION_MODE"; then
          processed_count=$(find data/processed -name "*.json" 2>/dev/null | wc -l || echo "0")
          echo "llm-processed=$processed_count" >> $GITHUB_OUTPUT
          echo "[OK] LLM processing completed: $processed_count properties"
        else
          echo "llm-processed=0" >> $GITHUB_OUTPUT
          echo "[WARN] LLM processing failed"
        fi
      timeout-minutes: 20
    
    - name: Data validation and reporting
      id: validation
      if: always()
      env:
        MONGODB_URL: ${{ secrets.MONGODB_URL }}
        COLLECTION_MODE: ${{ github.event.inputs.collection_mode || 'incremental' }}
      run: |
        echo "Running data validation..."
        
        # Generate collection summary
        maricopa_count="${{ steps.maricopa.outputs.maricopa-collected || '0' }}"
        mls_count="${{ steps.phoenix-mls.outputs.mls-collected || '0' }}"
        processed_count="${{ steps.llm-processing.outputs.llm-processed || '0' }}"
        
        total_collected=$((maricopa_count + mls_count))
        
        echo "Collection Summary:"
        echo "- Maricopa properties: $maricopa_count"
        echo "- Phoenix MLS properties: $mls_count"
        echo "- Total collected: $total_collected"
        echo "- LLM processed: $processed_count"
        
        # Determine overall status
        if [[ $total_collected -gt 0 ]]; then
          if [[ $processed_count -gt 0 ]]; then
            echo "status=success" >> $GITHUB_OUTPUT
            echo "[OK] Collection and processing completed successfully"
          else
            echo "status=partial" >> $GITHUB_OUTPUT
            echo "[WARN] Collection succeeded but processing incomplete"
          fi
        else
          echo "status=failure" >> $GITHUB_OUTPUT
          echo "[FAIL] No data collected"
        fi
        
        echo "properties-collected=$total_collected" >> $GITHUB_OUTPUT
    
    - name: Set job outputs
      id: status
      run: |
        echo "collection-status=${{ steps.validation.outputs.status }}" >> $GITHUB_OUTPUT
        echo "processing-status=${{ steps.llm-processing.outputs.llm-processed != '0' && 'success' || 'failed' }}" >> $GITHUB_OUTPUT
        echo "properties-collected=${{ steps.validation.outputs.properties-collected }}" >> $GITHUB_OUTPUT
    
    - name: Upload collection artifacts
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: production-collection-${{ github.run_number }}
        path: |
          data/raw/*.json
          data/processed/*.json
          data/cookies/*.pkl
          logs/*.log
          reports/*.json
        retention-days: 14

  notification-and-monitoring:
    name: Notification and Monitoring
    runs-on: ubuntu-latest
    needs: [collection-and-processing]
    if: always()
    timeout-minutes: 10
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Install dependencies for notifications
      run: |
        pip install uv
        uv sync --no-dev
    
    - name: Generate collection report
      env:
        COLLECTION_STATUS: ${{ needs.collection-and-processing.outputs.collection-status }}
        PROPERTIES_COLLECTED: ${{ needs.collection-and-processing.outputs.properties-collected }}
        ZIP_CODES: ${{ github.event.inputs.zip_codes || '85031,85033,85035' }}
        COLLECTION_MODE: ${{ github.event.inputs.collection_mode || 'incremental' }}
      run: |
        cat << EOF >> $GITHUB_STEP_SUMMARY
        # Daily Data Collection Report
        
        **Date**: $(date -u +"%Y-%m-%d %H:%M:%S UTC")
        **Status**: $COLLECTION_STATUS
        **Properties Collected**: $PROPERTIES_COLLECTED
        **ZIP Codes**: $ZIP_CODES
        **Collection Mode**: $COLLECTION_MODE
        
        **GitHub Actions Run**: [${{ github.run_id }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})
        
        ## Next Steps
        - Scheduled collection: Tomorrow at 3 AM Phoenix time
        - Monitor data quality and system health
        - Review any error logs if status is not success
        EOF
    
    - name: Send email notification
      if: always()
      env:
        EMAIL_ENABLED: ${{ secrets.EMAIL_ENABLED || 'false' }}
        COLLECTION_STATUS: ${{ needs.collection-and-processing.outputs.collection-status }}
        PROPERTIES_COLLECTED: ${{ needs.collection-and-processing.outputs.properties-collected }}
      run: |
        if [[ "$EMAIL_ENABLED" == "true" ]]; then
          echo "Email notifications configured - sending status update..."
          # Email script would go here when implemented
          echo "[INFO] Email notification would be sent: Status $COLLECTION_STATUS, Properties $PROPERTIES_COLLECTED"
        else
          echo "[INFO] Email notifications not configured"
        fi
    
    - name: Create failure issue
      if: needs.collection-and-processing.outputs.collection-status == 'failure'
      uses: actions/github-script@v7
      with:
        script: |
          const issueBody = `
          ## Production Data Collection Failed
          
          **Run ID**: ${{ github.run_id }}
          **Date**: ${new Date().toISOString()}
          **Properties Collected**: ${{ needs.collection-and-processing.outputs.properties-collected }}
          **ZIP Codes**: ${{ github.event.inputs.zip_codes || '85031,85033,85035' }}
          **Collection Mode**: ${{ github.event.inputs.collection_mode || 'incremental' }}
          
          ### Action Required
          - Check workflow logs for error details
          - Verify API credentials and service health
          - Consider manual collection if needed
          - Update this issue when resolved
          
          [View Run Logs](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})
          `;
          
          await github.rest.issues.create({
            owner: context.repo.owner,
            repo: context.repo.repo,
            title: `Production Collection Failed - ${new Date().toDateString()}`,
            body: issueBody,
            labels: ['automation', 'production', 'data-collection', 'failure', 'urgent']
          });
    
    - name: Trigger Success Notification
      if: needs.collection-and-processing.outputs.collection-status == 'success'
      uses: ./.github/workflows/success-notification.yml
      with:
        workflow-name: 'Production Data Collection'
        success-metrics: |
          {
            "properties_collected": ${{ needs.collection-and-processing.outputs.properties-collected }},
            "processing_time": 60,
            "success_rate": 100,
            "zip_codes_processed": ${{ github.event.inputs.zip_codes || '85031,85033,85035' | split(',') | length }},
            "collection_mode": "${{ github.event.inputs.collection_mode || 'incremental' }}",
            "workflow_run_id": "${{ github.run_id }}"
          }
        notification-context: |
          Successful data collection completed for ZIP codes: ${{ github.event.inputs.zip_codes || '85031,85033,85035' }}
          Collection mode: ${{ github.event.inputs.collection_mode || 'incremental' }}
          Total properties collected: ${{ needs.collection-and-processing.outputs.properties-collected }}
    
    - name: Trigger Issue Resolution on Recovery
      if: needs.collection-and-processing.outputs.collection-status == 'success'
      uses: ./.github/workflows/issue-resolution.yml
      with:
        trigger-event: 'data-collection-success'
        resolution-context: |
          Production data collection has been successfully restored.
          
          Collection Details:
          - Properties collected: ${{ needs.collection-and-processing.outputs.properties-collected }}
          - ZIP codes processed: ${{ github.event.inputs.zip_codes || '85031,85033,85035' }}
          - Collection mode: ${{ github.event.inputs.collection_mode || 'incremental' }}
          - Workflow run: ${{ github.run_id }}
        metrics: |
          {
            "properties_collected": ${{ needs.collection-and-processing.outputs.properties-collected }},
            "processing_time": 60,
            "success_rate": 100,
            "zip_codes_processed": ${{ github.event.inputs.zip_codes || '85031,85033,85035' | split(',') | length }},
            "collection_mode": "${{ github.event.inputs.collection_mode || 'incremental' }}",
            "timestamp": "${{ github.event.head_commit.timestamp || github.run_number }}",
            "workflow_run_id": "${{ github.run_id }}"
          }